{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hg8WfKU0BZWD"
   },
   "source": [
    "# **Project Omega**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoCIUXEFBbVS"
   },
   "source": [
    "# Project's Goal\n",
    "Our main research goal is to set a program that will predict the gender of the author from a tweet. Down the road, we have the ability to extend the model to any text.<br><br>\n",
    "To do so, we will use the following technics: \n",
    "\n",
    "\n",
    "*   Tokenization\n",
    "*   BOW (Bag Of Word)\n",
    "*   TF-IDF\n",
    "*   Cosine Similarity\n",
    "*   Logistic Regression\n",
    "*   Decision tree and random forest\n",
    "*   K-Nearest-Neighbors\n",
    "\n",
    "All of the technics mentionned above, have been studied during class hours.\n",
    "<br>\n",
    "\n",
    "In term of business, with this idea we aim to enhence marketing targeting. Third party advertisement companies can have better knowledge on Twitter’s gender distribution. Thus, they can advise companies that want to make advertisement on social network like Twitter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilTvvGBLBcYx"
   },
   "source": [
    "## Importation and Installation of methods\n",
    "For this project, we will use different packages. The main part will be about text mining. For this, we will use packages presented in class, which are *spacy*, *nltk* and *enchant*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZnVKnB6BxRI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /anaconda3/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Unable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk-13.jdk/Contents/Home/bin/apt\" (-1)\n",
      "Requirement already satisfied: pyenchant in /anaconda3/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: nltk in /anaconda3/lib/python3.7/site-packages (3.4.4)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /anaconda3/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "//anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "//anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Patrick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Patrick/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chart_studio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/3f/d2f3f506ba1aaf109f549f8b01d1483cd3e324c5ebe6b206acee66efdf46/chart_studio-1.0.0-py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 1.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from chart_studio) (2.22.0)\n",
      "Collecting retrying>=1.3.3 (from chart_studio)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n",
      "Collecting plotly (from chart_studio)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/ce/6ea5683c47b682bffad39ad41d10913141b560b1b875a90dbc6abe3f4fa9/plotly-4.4.1-py2.py3-none-any.whl (7.3MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3MB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from chart_studio) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->chart_studio) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->chart_studio) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->chart_studio) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests->chart_studio) (1.24.2)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Patrick/Library/Caches/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly, chart-studio\n",
      "Successfully installed chart-studio-1.0.0 plotly-4.4.1 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "!pip install spacy\n",
    "!apt install -qq enchant\n",
    "!pip install pyenchant\n",
    "!pip install nltk\n",
    "!python -m spacy download en\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "!pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USkSWdDbB7J8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import enchant\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQWwm9iIRcf_"
   },
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9AV_STwSQIi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created  ...                                       profileimage  \\\n",
       "0    12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1   10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2  11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3   6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4   4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "\n",
       "   retweet_count sidebar_color  \\\n",
       "0              0        FFFFFF   \n",
       "1              0        C0DEED   \n",
       "2              1        C0DEED   \n",
       "3              0        C0DEED   \n",
       "4              0             0   \n",
       "\n",
       "                                                text tweet_coord tweet_count  \\\n",
       "0  Robbie E Responds To Critics After Win Against...         NaN      110964   \n",
       "1  ÛÏIt felt like they were my friends and I was...         NaN        7471   \n",
       "2  i absolutely adore when louis starts the songs...         NaN        5617   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...         NaN        1693   \n",
       "4  Watching Neighbours on Sky+ catching up with t...         NaN       31462   \n",
       "\n",
       "    tweet_created      tweet_id   tweet_location               user_timezone  \n",
       "0  10/26/15 12:40  6.587300e+17  main; @Kan1shk3                     Chennai  \n",
       "1  10/26/15 12:40  6.587300e+17              NaN  Eastern Time (US & Canada)  \n",
       "2  10/26/15 12:40  6.587300e+17           clcncl                    Belgrade  \n",
       "3  10/26/15 12:40  6.587300e+17    Palo Alto, CA  Pacific Time (US & Canada)  \n",
       "4  10/26/15 12:40  6.587300e+17              NaN                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/XaviJunior/omega/Data/Data/gender-classifier-DFE-791531.csv',encoding=\"latin-1\")\n",
    "textgender=data[[\"gender\",'text',\"description\"]]\n",
    "textgender=textgender.dropna()\n",
    "X=textgender[['text','description']]\n",
    "y=textgender[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n",
    "train= pd.concat([X_train.reset_index(drop='Tru‌​e'),y_train.reset_index(drop='Tru‌​e')],axis=1)\n",
    "test=pd.concat([X_test.reset_index(drop='Tru‌​e'),y_test.reset_index(drop='Tru‌​e')],axis=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYv0JhESDI-P"
   },
   "source": [
    "# Cosine Similarity\n",
    "The first method we will apply, is the cosine-similarity. The later is frequently used for text-similarity.<br>\n",
    "Our first idea, was to apply the cosine similarity between all train tweets and test tweets. Then classify the tweet according to the most similar one. However, we realised that the data set was too big and it would take too much time to go through all the test tweets. (Our code ran an entire night and did not end the task) <br>\n",
    "So our second idea was to merge all train tweets and the description of each account (to gain text) in two documents: one with text written by male and another by female. With that, we will be able to gain more information such as most common words used by each gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWCLpvkhCJrf"
   },
   "source": [
    "## Data Cleaning <br>\n",
    "We began by separating tweet by gender. We made two new tables, one for male and one for female. <br>\n",
    "We are not interested by all the features (columns), we need to keep only \"gender\", \"text\" and \"name\" colums for the brand. <br>\n",
    "We chose to split the data by gender. Thus, we are able to construct a general BOW for each gender. As a tweet is necessarily written by a male or a female (only taking into account biological gender), we decided to ingnore tweets written by brand or tweets labeled as unknown because they won't help us to reach the goal we set at the beggining of this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nJkdmIQCAM_"
   },
   "outputs": [],
   "source": [
    "#New Table with Male Only and Split in Test/Train Data\n",
    "Male = train[train['gender'] == 'male']\n",
    "Maletext=Male['text']\n",
    "MaleDes=Male['description']\n",
    "ym=Male[\"gender\"]\n",
    "ListMale=Maletext.values.tolist()+MaleDes.values.tolist()\n",
    "\n",
    "#New Table with Female Only and split in Test/Train Data\n",
    "Female = train[train['gender'] == 'female']\n",
    "Femaletext=Female['text']\n",
    "FemaleDes=Female['description']\n",
    "yf=Female[\"gender\"]\n",
    "ListFemale=Femaletext.values.tolist()+FemaleDes.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCL_Td_rGR60"
   },
   "source": [
    "### Merging\n",
    "Since we created different tables for both gender. We will merge all the tweets in two documents, for one male and one for female. We do that because we are interested to know which words are the most used by male and female.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsI2CkaPGSbV"
   },
   "outputs": [],
   "source": [
    "#Merge all Male Text in a single string\n",
    "TextMale=\" \"\n",
    "for i in range(0,len(ListMale)):\n",
    "  TextMale=TextMale+ListMale[i]\n",
    "textmale=TextMale.lower()\n",
    "\n",
    "#Merge all Female Text in a single string\n",
    "TextFemale=\" \"\n",
    "for i in range(0,len(ListFemale)):\n",
    "  TextFemale=TextFemale+ListFemale[i]\n",
    "textfemale=TextFemale.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F67Xvy94GfVN"
   },
   "source": [
    "### Tokenization, Stop Words, Lemmatization\n",
    "Here, we created a function that will proceed text cleaning.<br>\n",
    "First, the tokenization will allow us to separate each word and to be able to calulate the frequency of every single word. The tokenization's technique chosen is the white-space one.<br>\n",
    "Now that we have tokens, we want to clean the text by removing stop words and other useless tokens such as \"\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\". To do so, we will use a stop words list available in spacy and filter words that are not in the english dictionnary available on pyenchant. We are aware that by using an english dictionnary we may lose some expression that are used on Twitter. But for us, it was the only sustainable solution to filter non-sense tokens. We will also test this function without the dictionnary to see which one gives use the best accuracy. <br>\n",
    "Finally we did some lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhW7tPE3Ga-V"
   },
   "outputs": [],
   "source": [
    "#Cleaning function\n",
    "def cleaning(input):\n",
    "  nlp = English()\n",
    "  Doc=nlp(input)\n",
    "  Token = []\n",
    "#Check if words in english dictionnary\n",
    "  for token in Doc:\n",
    "    Token.append(token.text)\n",
    "  Words=[]\n",
    "  d = enchant.Dict(\"en_US\")\n",
    "  Text=''\n",
    "  for i in Token:\n",
    "    if d.check(i)==True and i != ' ': #comment this line to try without dictionnary\n",
    "      Text+=' '+i         #remove an indenatation to try without dictionnary\n",
    "  doc=nlp(Text)\n",
    "#Remove stop words and punctuation\n",
    "  for word in doc:\n",
    "    if word.is_stop==False and word.is_punct==False:\n",
    "      Words.append(word)\n",
    "  words=''\n",
    "#Lemmatization\n",
    "  for j in Words:\n",
    "    lemm=lemmatizer.lemmatize(str(j))\n",
    "    words+=lemm+' '\n",
    "  words=words.lower()\n",
    "  return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJqRkoIB1jAd"
   },
   "outputs": [],
   "source": [
    "#Tokenizer found in the DMML class lab 6.1\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WpjF0ekVIXnI"
   },
   "source": [
    "Now, we will apply this function to both documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CNvczhFIdED"
   },
   "outputs": [],
   "source": [
    "Fem=cleaning(textfemale)\n",
    "Mal=cleaning(textmale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_2vlPzcJJ43"
   },
   "source": [
    "## Bag Of Words (BOW)\n",
    "Here we are going to create a table with a line per gender. The columns are all the words used on the train tweets of our dataset. As we merged all the tweets, it would have made no sense to set bag of words of n-grams other than n=1. Because at some point some BOW would have been written by two different people. We created two functions, the first is to plot the BOW for our female and male documents, the second one will plot the BOW with these documents and the tweet for which we want to predict the gender.<br>\n",
    "As we only have 2 documents, doing some TF-IDF would not make a lot of sence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnqcjybuJJPX"
   },
   "outputs": [],
   "source": [
    "#Creation and ploting of bag of words for two documents\n",
    "def bagofwords(Fem,Mal):\n",
    "  text=[Fem,Mal]\n",
    "  count = CountVectorizer()\n",
    "  bow = count.fit_transform(text)\n",
    "  feature_names = count.get_feature_names()\n",
    "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male'])\n",
    "  return BagOfWords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7FRgWtUKAee"
   },
   "outputs": [],
   "source": [
    "#Creation and ploting of bag of words for three documents\n",
    "def BOW(clean):\n",
    "  clean=cleaning(clean)\n",
    "  text=[Fem,Mal,clean]\n",
    "  count = CountVectorizer()\n",
    "  bow = count.fit_transform(text)\n",
    "  feature_names = count.get_feature_names()\n",
    "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male','Test'])\n",
    "  return BagOfWords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6k4E3hhKMIJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000000000000002344</th>\n",
       "      <th>01</th>\n",
       "      <th>01234</th>\n",
       "      <th>017</th>\n",
       "      <th>01912843723</th>\n",
       "      <th>0305</th>\n",
       "      <th>031012</th>\n",
       "      <th>04</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zonked</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  00000000000000002344  01  01234  017  01912843723  0305  \\\n",
       "Female   2    4                     1   3      0    0            0     0   \n",
       "Male     0   16                     0   2      1    1            1     1   \n",
       "\n",
       "        031012  04  ...  zip  zodiac  zombie  zone  zoning  zonked  zoo  \\\n",
       "Female       0   2  ...    0       1       3     2       0       1    1   \n",
       "Male         1   0  ...    1       2      11     4       1       0    3   \n",
       "\n",
       "        zoologist  zoom  zooming  \n",
       "Female          2     0        1  \n",
       "Male            1     1        0  \n",
       "\n",
       "[2 rows x 10849 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords(Fem,Mal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfENjkIWKqzi"
   },
   "source": [
    "## Cleaning of the Test Data\n",
    "This part is a little bit more technical than the first cleaning we did. In the first case, we merged all tweet so we had only two documents. <br>\n",
    "Now, we want to clean tweet by tweet and have several clean documents. As we cleaned the *train* set, we need to apply the same method to the *test* set. The goal of this section is to build a list of *cleaned tweets* by gender. <br>\n",
    "This time, knowing that our goal is to predict gender by tweet only, we won't take into account the account's description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQA_9O6iKqd6"
   },
   "outputs": [],
   "source": [
    "#Here, we will set the test set as random mix of tweet.\n",
    "TestSet = test[(test.gender=='male') | (test.gender=='female')]\n",
    "X_test=TestSet[\"text\"]\n",
    "y_test=TestSet[\"gender\"]\n",
    "Test=X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8qbZFkXoL27"
   },
   "outputs": [],
   "source": [
    "Clean_Test=[]\n",
    "for i in Test:\n",
    "  Clean_Test.append(spacy_tokenizer(i))\n",
    "Test_Clean=[]\n",
    "for i in range(0, len(Clean_Test)):\n",
    "  Test_Clean.append(' '.join(Clean_Test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PW_1GEGuNeFw"
   },
   "source": [
    "## Classifying\n",
    "Now, the funny part begins! As explained before, the first method chosen is the cosine-similarity. To do so, we created a function that will compute the cosine-similarity of each test tweet with our two documents (female's one and male's one). The function will classify the tweet accordingly to the highest cosine-similarity. In our case, the base rate is female, but in case of an equality situation between the cosine-similarities, we will classify the tweet as a female. Anyway, we will check the baserate for the overall twitter base user and not for our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFMtgjE4NiJw"
   },
   "outputs": [],
   "source": [
    "#Classification with Cosine Similarity\n",
    "def classifier(clean):\n",
    "  clean=cleaning(clean)\n",
    "  y_pred=[]\n",
    "  text=[Fem,Mal,clean]\n",
    "  count = CountVectorizer()\n",
    "  bow = count.fit_transform(text)\n",
    "  cosine =cosine_similarity(bow[2],bow)\n",
    "  if cosine[0][0]>=cosine[0][1]:\n",
    "    y_pred.append(\"female\")\n",
    "  else:\n",
    "    y_pred.append(\"male\")\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fULfmoTNO4HB"
   },
   "outputs": [],
   "source": [
    "#might take some time as we have a lot of data, model not optimized...\n",
    "y_pred=[]\n",
    "for i in Test_Clean:\n",
    "  y_pred.append(classifier(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioop0aV6jcVl"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inzS1gjdbM23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5782222222222222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nbj7q5uodbGh"
   },
   "source": [
    "We see that our accuracy is higher than the BaseRate of the model. It means that the accuracy will be higher by using our model than classifying every tweet as written by female. But the difference is not huge. Therefor, we will try with another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ys0QcggMe6rT"
   },
   "source": [
    "### Predict Tweet's gender\n",
    "Here, you can input a tweet of your choice and our model will try to predict the author's gender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxLGS_tOeXli"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Tweet: Bonjour je m'appelle bibi\n",
      "This tweet was probably written by a: ['female']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000000000000002344</th>\n",
       "      <th>01</th>\n",
       "      <th>01234</th>\n",
       "      <th>017</th>\n",
       "      <th>01912843723</th>\n",
       "      <th>0305</th>\n",
       "      <th>031012</th>\n",
       "      <th>04</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zonked</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  00000000000000002344  01  01234  017  01912843723  0305  \\\n",
       "Female   2    4                     1   3      0    0            0     0   \n",
       "Male     0   16                     0   2      1    1            1     1   \n",
       "Test     0    0                     0   0      0    0            0     0   \n",
       "\n",
       "        031012  04  ...  zip  zodiac  zombie  zone  zoning  zonked  zoo  \\\n",
       "Female       0   2  ...    0       1       3     2       0       1    1   \n",
       "Male         1   0  ...    1       2      11     4       1       0    3   \n",
       "Test         0   0  ...    0       0       0     0       0       0    0   \n",
       "\n",
       "        zoologist  zoom  zooming  \n",
       "Female          2     0        1  \n",
       "Male            1     1        0  \n",
       "Test            0     0        0  \n",
       "\n",
       "[3 rows x 10850 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Congratulations to Boris Johnson on his great WIN! Britain and the United States will now be free to strike a massive new Trade Deal after BREXIT. This deal has the potential to be far bigger and more lucrative than any deal that could be made with the E.U. Celebrate Boris!\n",
    "Tweet=input(\"Enter a Tweet: \")\n",
    "print('This tweet was probably written by a:',classifier(Tweet))\n",
    "BOW(Tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEKQdPKDhYWD"
   },
   "source": [
    "# Logistic Regression - Sentiment Analysis Model\n",
    "In this part, we will predict the gender with a logistic Regression. To do so, we will try to adapt a *Sentiment Analysis* model. The equivalent of the sentiment will be the gender. To do so, we won't use the merge documents for the training part. We will keep all tweets as an input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YevtietiKij"
   },
   "source": [
    "## Data Cleaning\n",
    "For this model, we need to clean all our tweets one by one. This time, we won't use the description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqer-dXTT2Z0"
   },
   "outputs": [],
   "source": [
    "TrainSet = train[(train.gender=='male') | (train.gender=='female')]\n",
    "X_train=TrainSet[\"text\"]\n",
    "y_train=TrainSet[\"gender\"]\n",
    "Train=X_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-fEV7OeKgwY"
   },
   "outputs": [],
   "source": [
    "Clean_Train=[]\n",
    "for i in Train:\n",
    "  Clean_Train.append(spacy_tokenizer(i))\n",
    "Train_Clean=[]\n",
    "for i in range(0, len(Clean_Train)):\n",
    "  Train_Clean.append(' '.join(Clean_Train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HnIIDgFjRts"
   },
   "source": [
    "## Classifying\n",
    "For this model, we will use a cleaning function that was given during our DMML class (see lab 6.1). The cleaning methods works better with this model than the function we wrote ourself. However, our function is better with the cosine-similarity than that cleaning's function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_kAcabThtwG"
   },
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier2 = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier2', classifier2)])\n",
    "\n",
    "# model generation\n",
    "y_train=TrainSet[\"gender\"]\n",
    "pipe.fit(Train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WP1zS9kAZE3w"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3VivyKRjAVK"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(Test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbLiJ_1DZRaf"
   },
   "source": [
    "We conclude that the accuracy in this case is quite similar to the accuracy obtained with the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaZ-nevwcz_b"
   },
   "source": [
    "### Predict Tweet's gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pV2qdQ7bc9RQ"
   },
   "outputs": [],
   "source": [
    "Tweet=input(\"Enter a Tweet: \")\n",
    "Tweet=[Tweet]\n",
    "print('This tweet was probably written by a:',pipe.predict(Tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxCzWPwwQa_-"
   },
   "source": [
    "# SK-Learn techniques\n",
    "As we are not satisfied by our accuracy, we will try other methods. Here we will use the differents methods available on the Scikit-Learn library. For this method, the input of the model cannot be a list of words. We will input array that can be represent graphically as bag of words. To construct this method, we took example of the Lab Session of the DMML class. We will use the data that we cleaned previously and transform them in arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtrSBmB0tt9C"
   },
   "source": [
    "## Data transformation\n",
    "In this part, we will transform ours lists of words into array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "445F877TQomv"
   },
   "outputs": [],
   "source": [
    "Train_texts = Train_Clean\n",
    "#transform the list of words into array\n",
    "count = CountVectorizer()\n",
    "count2=CountVectorizer(ngram_range=(1, 2))\n",
    "bow_train = count.fit_transform(Train_texts)\n",
    "bow_train2=count2.fit_transform(Train_texts)\n",
    "bow_train.toarray()\n",
    "bow_train2.toarray()\n",
    "feature_names = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47KK5qQxQ64L"
   },
   "outputs": [],
   "source": [
    "#Add a column with the gender and transfrom 'male' as 0 and 'female' as 1\n",
    "y_train=TrainSet[\"gender\"]\n",
    "y_train= y_train.replace({'male':0})\n",
    "y_train = y_train.replace({'female':1})\n",
    "y_train=y_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-eOSVc7V8nD"
   },
   "outputs": [],
   "source": [
    "#transform the list of words into array\n",
    "y_test=TestSet['gender']\n",
    "Texts_test = Test_Clean \n",
    "bow_test = count.transform(Texts_test)\n",
    "bow_test2 = count2.transform(Texts_test)\n",
    "bow_test.toarray()\n",
    "bow_test2.toarray()\n",
    "#Change the value of the test set as it matches the train one\n",
    "y_test=y_test.replace({'male':0})\n",
    "y_test=y_test.replace({'female':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UGj764WuHqZ"
   },
   "source": [
    "## Bag Of Words DataFrame\n",
    "The columns of this dataframe represent all words available in our dataset. To win some time, we didn't use the english dictionnary in the cleaning process. We have some non-sense token but on the other hand, we can capture some words that are only use on social-networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxgG8E5aQ1wc"
   },
   "outputs": [],
   "source": [
    "#Create a bag of words DataFrame\n",
    "BoW=pd.DataFrame(\n",
    "    bow_train.todense(), \n",
    "    columns=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwK6LtVsQ-UX"
   },
   "outputs": [],
   "source": [
    "#with n-gram 1 and 2, it might crash\n",
    "BoW['Gender']=y_train\n",
    "cols = list(BoW.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "BoW = BoW[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZQY6zViRB6_"
   },
   "outputs": [],
   "source": [
    "#Display the BagOfWords\n",
    "BoW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Po2qbk53RPQE"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf_train = tfidf.fit_transform(Train_texts)\n",
    "tfidf_train.toarray()\n",
    "TFIDF=pd.DataFrame(tfidf_train.todense(),columns=tfidf.get_feature_names())\n",
    "TFIDF['Gender']=y_train\n",
    "cols = list(TFIDF.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "TFIDF = TFIDF[cols]\n",
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bycvt1kgsz8c"
   },
   "outputs": [],
   "source": [
    "tfidf_test=tfidf.transform(Texts_test)\n",
    "tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q_RloF3unfq"
   },
   "source": [
    "## Dimensionality-Reduction\n",
    "As we saw in the last lecture, we can gain in accuracy and in computing time by applying dimensionality-reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcEjUDmTskrt"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse as sp\n",
    "clf = TruncatedSVD()\n",
    "Xpca_Test = clf.fit_transform(bow_test)\n",
    "Xpca_Train = clf.fit_transform(bow_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTBdbdotmLcr"
   },
   "source": [
    "Now, from this part, we have clean all the data we need. So the end of the notebook will consist of training different models and computre their accuracy. That's why it will be less commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr6E_9bEuNeH"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be5dxjLBQy20"
   },
   "outputs": [],
   "source": [
    "#define the classifier, the max_depth parameter is defined thanks to a \"test\" done later\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=781,random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zTZFTT9uXJY"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9VxKPKzQysL"
   },
   "outputs": [],
   "source": [
    "#Train the model, first we no dimensionality reduction\n",
    "clf.fit(bow_train, y_train)\n",
    "clf.score(bow_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gi8xp-r77uhG"
   },
   "outputs": [],
   "source": [
    "#try with n-grams=1,2\n",
    "clf.fit(bow_train2,y_train)\n",
    "clf.score(bow_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypMCMovywiNe"
   },
   "outputs": [],
   "source": [
    "#try with TF-IDF\n",
    "clf.fit(tfidf_train,y_train)\n",
    "clf.score(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh-LraSFiZj9"
   },
   "outputs": [],
   "source": [
    "#train and test the model after the dimensionality reduction --> result is worst than the base-rate...\n",
    "clf.fit(Xpca_Train, y_train)\n",
    "clf.score(Xpca_Test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kz-998eIAMpX"
   },
   "source": [
    "Best accuracy with n-gram n=1. <br>\n",
    "The accuracy of this model is quite good. But to try to improve it, we will use another model based on decision tree: *Random Forest Classifier*. This model is descibed later. <br>\n",
    "We could have represent the model graphically, but as we set an optimal depth at 781, it would not have been readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bce_kv_RfjNq"
   },
   "source": [
    "### Test the Best Depth\n",
    "Here, we will try to find the optimum depth of our decision tree. The result for the depth are pretty sursprinsing. One can think that small depth would be better and other can think the opposite. But in fact, we cannot tell what is the best. The accuracy can increase with the depth but can also decrease. It looks like it is a little bit random..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TuhgDWbfZCCh"
   },
   "outputs": [],
   "source": [
    "#if you don't want to run it, optimum : Depth =781   Accuracy=58.2 % --> we may increase the range... or reduce the steps..\n",
    "max_acc=0\n",
    "depth=0\n",
    "for i in range(1,1000,5):\n",
    "  clf = DecisionTreeClassifier(criterion='entropy',max_depth=i,random_state=14)\n",
    "  clf.fit(bow_train, y_train)\n",
    "  if clf.score(bow_test,y_test) > max_acc:\n",
    "    max_acc= clf.score(bow_test,y_test)\n",
    "    depth=i\n",
    "    print('depth:', i,' acc =', max_acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJ2V7K5vCB0Q"
   },
   "source": [
    "### Predict Tweet's gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4IP4AsLCBWV"
   },
   "outputs": [],
   "source": [
    "clf.fit(bow_train, y_train)\n",
    "Tweet=input('Enter a Tweet: ')\n",
    "Tweet=[Tweet]\n",
    "bow_tweet= count.transform(Tweet)\n",
    "bow_tweet=bow_tweet.toarray()\n",
    "Gender=clf.predict(bow_tweet)\n",
    "if Gender ==0:\n",
    "  Gender='male'\n",
    "else:\n",
    "  Gender='female'\n",
    "print('This tweet was probably written by a:',Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4Zd5Rpdypfo"
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bydTCQenyET7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rclf=RandomForestClassifier(criterion='entropy',max_depth=371, random_state=14, n_estimators=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3ymkhVZyykc"
   },
   "outputs": [],
   "source": [
    "rclf.fit(bow_train,y_train)\n",
    "rclf.score(bow_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljWZgZUs8j1c"
   },
   "outputs": [],
   "source": [
    "#Try with n-grams n=1,2\n",
    "rclf.fit(bow_train2,y_train)\n",
    "rclf.score(bow_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOUPKJspIISm"
   },
   "outputs": [],
   "source": [
    "#try with TF-IDF\n",
    "rclf.fit(tfidf_train,y_train)\n",
    "rclf.score(tfidf_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5hYMeYt93Z6"
   },
   "outputs": [],
   "source": [
    "#train and test the model after the dimensionality reduction --> result is worst than the base-rate...\n",
    "rclf.fit(Xpca_Train, y_train)\n",
    "rclf.score(Xpca_Test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5E9R7Ck_5qO"
   },
   "source": [
    "### Test of the \"best\" parameters\n",
    "We will focus on two distinct parameters: depth and n_estimators. The optimal way to find the best parameters is to do iteration on depth and n_estimators on the same time. For example, for depth = 1 try all n_estimators between 1 and 1000. Then do the same with depth =2. It would have taken to much time. We decided to find the best depth with the default n_estimators (=10). Then having the best depth, we iterated the number of estimators according this depth. <br>\n",
    "Like before, we cannot say if small number or big number are better or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asHeE6vx4Yir"
   },
   "outputs": [],
   "source": [
    "#depth: 371  acc = 0.5964444444444444\n",
    "max_acc=0\n",
    "depth=0\n",
    "for i in range(1,1000,5):\n",
    "  rclf=RandomForestClassifier(criterion='entropy',max_depth=i, random_state=14,n_estimators=10)\n",
    "  rclf.fit(bow_train, y_train)\n",
    "  if rclf.score(bow_test,y_test) > max_acc:\n",
    "    max_acc= rclf.score(bow_test,y_test)\n",
    "    depth=i\n",
    "    print('depth:', i,' acc =', max_acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGYHQreI5ouy"
   },
   "outputs": [],
   "source": [
    "#Nothing was higher than the combination depth=371 and n_estimators=76 --> to find the best combination, should have done iterations on the both parameters but would have taken to much time \n",
    "max_acc=0\n",
    "n_estim=0\n",
    "for i in range(1,1000,5):\n",
    "  rclf=RandomForestClassifier(criterion='entropy',max_depth=371, random_state=14,n_estimators=i)\n",
    "  rclf.fit(bow_train, y_train)\n",
    "  if rclf.score(bow_test,y_test) > max_acc:\n",
    "    max_acc= rclf.score(bow_test,y_test)\n",
    "    n_estim=i\n",
    "    print('n_estim:', i,' acc =', max_acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRri99Vd_kdg"
   },
   "source": [
    "Best accuracy with n-gram n=1, max_depth= 371 and n_estimators = 76. Not all the combinations were tested.<br>\n",
    "This is the model that gives the best accuracy of this notebook. For us, this result is possible thanks to the way a random forest works. Having multiple random decision trees increases our chance of having better predictions than using only one decision tree. Because a tweet is not a long text, it is useful to try different variant of classification on it. It is exactly how works a random forest, a tweet may not be classified the same way for every tree of the forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyM9IMDG_eWj"
   },
   "source": [
    "### Predict Tweet's gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Nb3pwAQHwHY"
   },
   "outputs": [],
   "source": [
    "rclf.fit(bow_train, y_train)\n",
    "Tweet=input('Enter a Tweet: ')\n",
    "Tweet=[Tweet]\n",
    "bow_tweet= count.transform(Tweet)\n",
    "bow_tweet=bow_tweet.toarray()\n",
    "Gender=rclf.predict(bow_tweet)\n",
    "if Gender ==0:\n",
    "  Gender='male'\n",
    "else:\n",
    "  Gender='female'\n",
    "print('This tweet was probably written by a:',Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V58Kqmetub5F"
   },
   "source": [
    "## Basic Logistic Regression\n",
    "Let's try a more 'basic' regression. This one should not give weight to words as the one working as a sentiment analysis does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "celbkXGLD8bm"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "LR = LogisticRegressionCV(solver='lbfgs', cv=5,max_iter=1000, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0MoYG9cJBtB"
   },
   "outputs": [],
   "source": [
    "LR.fit(bow_train,y_train)\n",
    "LR.score(bow_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfGW9_X99ACO"
   },
   "outputs": [],
   "source": [
    "#Try with n-grams n=1,2\n",
    "LR.fit(bow_train2,y_train)\n",
    "LR.score(bow_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1yWtPnHwrYt"
   },
   "outputs": [],
   "source": [
    "#try with TF-IDF\n",
    "LR.fit(tfidf_train,y_train)\n",
    "LR.score(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkjKlpugjkKT"
   },
   "outputs": [],
   "source": [
    "#With dimensionality reduction\n",
    "LR.fit(Xpca_Train, y_train)\n",
    "LR.score(Xpca_Test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elrLdro2-4_J"
   },
   "source": [
    "Best accuracy n-gram n=1.<br>\n",
    "This model gives one of the best result with an accuracy of 60%. But a downside is that it takes more time than the other to do the computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYWqHQqzC9dm"
   },
   "source": [
    "### Predict Tweet's gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWtRSiBfC9DS"
   },
   "outputs": [],
   "source": [
    "LR.fit(bow_train, y_train)\n",
    "Tweet=input('Enter a Tweet: ')\n",
    "Tweet=[Tweet]\n",
    "bow_tweet= count.transform(Tweet)\n",
    "bow_tweet=bow_tweet.toarray()\n",
    "Gender=LR.predict(bow_tweet)\n",
    "if Gender ==0:\n",
    "  Gender='male'\n",
    "else:\n",
    "  Gender='female'\n",
    "print('This tweet was probably written by a:',Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRjE8EfHugUQ"
   },
   "source": [
    "## KNN Classification\n",
    "The last method we will try is a the k-nearest-neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkdhBFe9OnXR"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxRLEqfLjoIc"
   },
   "outputs": [],
   "source": [
    "knn.fit(bow_train,y_train)\n",
    "knn.score(bow_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1TOALk69a4q"
   },
   "outputs": [],
   "source": [
    "#Try with n-grams n=1,2\n",
    "knn.fit(bow_train2,y_train)\n",
    "knn.score(bow_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEdPSDhXwvjB"
   },
   "outputs": [],
   "source": [
    "#try with TF-IDF\n",
    "knn.fit(tfidf_train,y_train)\n",
    "knn.score(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAIDJvfijp7J"
   },
   "outputs": [],
   "source": [
    "#With dimensionality reduction\n",
    "knn.fit(Xpca_Train,y_train)\n",
    "knn.score(Xpca_Test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TuhVyD7i-u2d"
   },
   "source": [
    "Best accuracy with TF-IDF and n-gram n=1.<br>\n",
    "This is the only model that works better with an input different of a bag of words with n-gram. The best accuracy of this model is the one using the TF-IDF approach. <br>\n",
    "Something intersting with the KNN method is that we can set weight or not. In this case, it makes sense to give weight to the closest points. The nearest it will be, the most impact it will have on the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c59M0eUDLwT"
   },
   "source": [
    "### Predict Tweet's gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8WarPsHDA9K"
   },
   "outputs": [],
   "source": [
    "knn.fit(bow_train,y_train)\n",
    "Tweet=input('Enter a Tweet: ')\n",
    "Tweet=[Tweet]\n",
    "bow_tweet= count.transform(Tweet)\n",
    "bow_tweet=bow_tweet.toarray()\n",
    "Gender=knn.predict(bow_tweet)\n",
    "if Gender ==0:\n",
    "  Gender='male'\n",
    "else:\n",
    "  Gender='female'\n",
    "print('This tweet was probably written by a:',Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUlReYD03eGP"
   },
   "source": [
    "# Gender Prediction\n",
    "In this part, we will use all the methods tested before. The goal is to take all the predictions and to see which vote (male or female) is the most frequent. To do so, we will use the basic version of each method. (i.e. the one without dimensionality reduction). For the fit, we chose the one with the best accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZn_NC4pKY2j"
   },
   "outputs": [],
   "source": [
    "#re-fit the algo with the input data\n",
    "knn.fit(tfidf_train,y_train)\n",
    "LR.fit(bow_train,y_train)\n",
    "clf.fit(bow_train,y_train)\n",
    "rclf.fit(bow_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nZQadk73Ea3"
   },
   "outputs": [],
   "source": [
    "def GenderPrediction():\n",
    "  Results=[]\n",
    "  Tweet=input('Enter a Tweet or a Text: ')\n",
    "  Results.append(classifier(Tweet))\n",
    "  Tweet=[Tweet]\n",
    "  Results.append(pipe.predict(Tweet))\n",
    "  bow_tweet= count.transform(Tweet)\n",
    "  tfidf_tweet=tfidf.transform(Tweet)\n",
    "  tfidf_tweet=tfidf_tweet.toarray()\n",
    "  bow_tweet=bow_tweet.toarray()\n",
    "  Results.append(knn.predict(tfidf_tweet))\n",
    "  Results.append(LR.predict(bow_tweet))\n",
    "  Results.append(clf.predict(bow_tweet))\n",
    "  Results.append(rclf.predict(bow_tweet))\n",
    "  Pred_F=0\n",
    "  Pred_M=0\n",
    "  for i in Results:\n",
    "    if i[0] == 0 or i[0] =='male':\n",
    "      Pred_M +=1\n",
    "    else:\n",
    "      Pred_F+=1\n",
    "  if Pred_M>Pred_F:\n",
    "    print('This tweet was probably written by a male.')\n",
    "  else:\n",
    "    print('This tweet was probably written by a female.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fq-KtxSS3yX3"
   },
   "outputs": [],
   "source": [
    "GenderPrediction()\n",
    "#Congrations to Boris Johnson on his great WIN! Britain and the United States will now be free to strike a massive new Trade Deal after BREXIT. This deal has the potential to be far bigger and more lucrative than any deal that could be made with the E.U. Celebrate Boris! By our friend Donald Trump\n",
    "\n",
    "#No matter where we or our ancestors are from, millions of Americans will sit down together to break bread today. It's a wonderful reminder that our country is both a place and an idea—where anyone can find a home to breathe free. Happy Thanksgiving! By his friend Hillary Clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p36tmYzpLQHw"
   },
   "source": [
    "# Conclusion\n",
    "To sum up, we found that predicting the gender of someone by analysing his/her tweet is not an easy task. It might be due to the fact that a tweet is not long enough to collect enough data about the author. It may be interesting to adapt the model to longer text such as university thesis or books.<br>\n",
    "\n",
    "We could also extend the model to famous author and try to indentify their own writting style. And why not try to write a story according their style. (Something similar to what was done with Rembrandt's painting).)<br>\n",
    "However, the majortiy of our techniques led to an accuracy that was higher than the base rate. It means that our model is not useless.<br>\n",
    "We also tried to apply some dimensionality reduction. The result of that process was disappointing. It may be not appropriate to our model or we were maybe not able to use it properly.<br>\n",
    "We applied TF-IDF and n-grams n=1,2 for all the model. It only increased the accuracy for the knn model. Our best accuracy was with a random forest model. An accuracy of 61%, which is 10 points of pourcentage more than the base rate.\n",
    "Finally, the business solution will use all the techniques tried. It will predict the gender according to the one receiving the most of \"votes\" from the different methods."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DM-ML_Omega.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
