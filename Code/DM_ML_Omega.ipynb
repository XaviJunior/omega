{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM-ML_Omega.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg8WfKU0BZWD",
        "colab_type": "text"
      },
      "source": [
        "#**Project Omega**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoCIUXEFBbVS",
        "colab_type": "text"
      },
      "source": [
        "#Project's Goal\n",
        "Our main research goal is to set a program that will predict the gender of the author from a tweet. Down the road, we have the ability to extend the model to any text.<br><br>\n",
        "To do so, we will use the following technics: \n",
        "\n",
        "\n",
        "*   Tokenization\n",
        "*   BOW (Bag Of Word)\n",
        "*   TF-IDF\n",
        "*   Cosine Similarity\n",
        "*   Logistic Regression\n",
        "*   Decision tree and random forest\n",
        "*   K-Nearest-Neighbors\n",
        "\n",
        "All of the technics mentionned above, have been studied during class hours.\n",
        "<br>\n",
        "\n",
        "In term of business, with this idea we aim to enhence marketing targeting. Third party advertisement companies can have better knowledge on Twitter’s gender distribution. Thus, they can advise companies that want to make advertisement on social network like Twitter. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTvvGBLBcYx",
        "colab_type": "text"
      },
      "source": [
        "##Importation and Installation of methods\n",
        "For this project, we will use different packages. The main part will be about text mining. For this, we will use packages presented in class, which are *spacy*, *nltk* and *enchant*. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZnVKnB6BxRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "!pip install spacy\n",
        "!apt install -qq enchant\n",
        "!pip install pyenchant\n",
        "!pip install nltk\n",
        "!python -m spacy download en\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!pip install chart_studio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkSWdDbB7J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import enchant\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score\n",
        "import collections\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9AV_STwSQIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/XaviJunior/omega/Data/Data/gender-classifier-DFE-791531.csv',encoding=\"latin-1\")\n",
        "textgender=data[[\"gender\",'text',\"description\"]]\n",
        "textgender=textgender.dropna()\n",
        "X=textgender[['text','description']]\n",
        "y=textgender[\"gender\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n",
        "train= pd.concat([X_train.reset_index(drop='Tru‌​e'),y_train.reset_index(drop='Tru‌​e')],axis=1)\n",
        "test=pd.concat([X_test.reset_index(drop='Tru‌​e'),y_test.reset_index(drop='Tru‌​e')],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYv0JhESDI-P",
        "colab_type": "text"
      },
      "source": [
        "#Cosine Similarity\n",
        "The first method we will apply, is the cosine-similarity. The later is frequently used for text-similarity.<br>\n",
        "Our first idea, was to apply the cosine similarity between all train tweets and test tweets. Then classify the tweet according to the most similar one. However, we realised that the data set was too big and it would take too much time to go through all the test tweets. (Our code runs an entire night and did not end the task) <br>\n",
        "So our second idea was to merge all train tweet and the description of each account (to gain text) as two documents, one with text written by male and another by female. With that, we will be able to gain more information such as most common words used by each gender.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWCLpvkhCJrf",
        "colab_type": "text"
      },
      "source": [
        "##Data Cleaning <br>\n",
        "We began by separating tweet by gender. We made two new tables, one for male and one for female. <br>\n",
        "We are not interested by all the feautres (columns), we need to keep only the \"gender\", the \"text\" and the \"name\" colums for the brand. <br>\n",
        "We chose to split the data by gender. Thus, we are able to construct a general BOW for each gender. As a tweet is necessarily written by a male or a female (only taking into account biological gender), for our train and test set. We decided to ingonre tweet written by *brand* or tweet labeled as *unknown* because they won't help us to reach the goal we set at the beggining of this project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJkdmIQCAM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#New Table with Male Only and Split in Test/Train Data\n",
        "Male = train[train['gender'] == 'male']\n",
        "Maletext=Male['text']\n",
        "MaleDes=Male['description']\n",
        "ym=Male[\"gender\"]\n",
        "ListMale=Maletext.values.tolist()+MaleDes.values.tolist()\n",
        "\n",
        "#New Table with Female Only and split in Test/Train Data\n",
        "Female = train[train['gender'] == 'female']\n",
        "Femaletext=Female['text']\n",
        "FemaleDes=Female['description']\n",
        "yf=Female[\"gender\"]\n",
        "ListFemale=Femaletext.values.tolist()+FemaleDes.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCL_Td_rGR60",
        "colab_type": "text"
      },
      "source": [
        "###Merging\n",
        "Since we created different tables for both gender. We will merge all the tweets in two documents, for one male and one for female. We do that because we are interested to know which words are the most used by male and female.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsI2CkaPGSbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merge all Male Text in a single string\n",
        "TextMale=\" \"\n",
        "for i in range(0,len(ListMale)):\n",
        "  TextMale=TextMale+ListMale[i]\n",
        "textmale=TextMale.lower()\n",
        "\n",
        "#Merge all Female Text in a single string\n",
        "TextFemale=\" \"\n",
        "for i in range(0,len(ListFemale)):\n",
        "  TextFemale=TextFemale+ListFemale[i]\n",
        "textfemale=TextFemale.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67Xvy94GfVN",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization, Stop Words, Lemmatization\n",
        "Here, we created a function that will proceed text cleaning.<br>\n",
        "First, the tokenization will allow us to separate each word and to be able to calulate the frequency of every single word. The tokenization's technique chosen is the white-space one.<br>\n",
        "Now that we have tokens, we want to clean the text by removing stop words and other useless tokens such as \"\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\". To do so, we will use a stop words list available in *spacy* and filter words that are not in the english dictionnary available on *pyenchant*. We know that by using an ensglish dictionnary we may lose some expression that are used on twitter. But for us, it was the only sustainable solution to filter non-sense tokens. We will also test this function without the dictionnary to see which one gives use the best accuracy. <br>\n",
        "Finally we did some lemmatization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhW7tPE3Ga-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning function\n",
        "def cleaning(input):\n",
        "  nlp = English()\n",
        "  Doc=nlp(input)\n",
        "  Token = []\n",
        "#Check if words in english dictionnary\n",
        "  for token in Doc:\n",
        "    Token.append(token.text)\n",
        "  Words=[]\n",
        "  d = enchant.Dict(\"en_US\")\n",
        "  Text=''\n",
        "  for i in Token:\n",
        "    if d.check(i)==True and i != ' ': #comment this line to try without dictionnary\n",
        "      Text+=' '+i         #remove an indenatation to try without dictionnary\n",
        "  doc=nlp(Text)\n",
        "#Remove stop words and punctuation\n",
        "  for word in doc:\n",
        "    if word.is_stop==False and word.is_punct==False:\n",
        "      Words.append(word)\n",
        "  words=''\n",
        "#Lemmatization\n",
        "  for j in Words:\n",
        "    lemm=lemmatizer.lemmatize(str(j))\n",
        "    words+=lemm+' '\n",
        "  words=words.lower()\n",
        "  return(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJqRkoIB1jAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizer found in the DMML class lab 6.1\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpjF0ekVIXnI",
        "colab_type": "text"
      },
      "source": [
        "Now, we will apply this function to both documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CNvczhFIdED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fem=cleaning(textfemale)\n",
        "Mal=cleaning(textmale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_2vlPzcJJ43",
        "colab_type": "text"
      },
      "source": [
        "##Bag Of Words (BOW)\n",
        "Here we are going to create a table with a line per gender. The columns are all the words used on the train tweet of our dataset. As we merge all the tweet, it would have made no sense to set bag of words of n-gramns other than one. Because at some point some BOW would have been wirtten by two different people. We create two functions, the first is to plot the BOW for our *female* and *male* documents, the second one will plot the BOW with these documents and the tweet for which we want to predict the gender.<br>\n",
        "As we only have 2 documents, doing some TF-IDF would not make a lot of sence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqcjybuJJPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creation and ploting of bag of words for two documents\n",
        "def bagofwords(Fem,Mal):\n",
        "  text=[Fem,Mal]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  feature_names = count.get_feature_names()\n",
        "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male'])\n",
        "  return BagOfWords.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7FRgWtUKAee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creation and ploting of bag of words for three documents\n",
        "def BOW(clean):\n",
        "  clean=cleaning(clean)\n",
        "  text=[Fem,Mal,clean]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  feature_names = count.get_feature_names()\n",
        "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male','Test'])\n",
        "  return BagOfWords.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6k4E3hhKMIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bagofwords(Fem,Mal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfENjkIWKqzi",
        "colab_type": "text"
      },
      "source": [
        "##Cleaning of the Test Data\n",
        "This part is a little bit more technical than the first cleaning we did. In the first case, we merged all tweet so we had only two documents. <br>\n",
        "Now, we want to clean tweet by tweet and have several clean documents. As we cleaned the *train* set, we need to apply the same method to the *test* set. The goal of this section is to build a list of *cleaned tweets* by gender. <br>\n",
        "This time, knowing that our goal is to predict gender by tweet only, we won't take into account the account's description\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQA_9O6iKqd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here, we will set the test set as random mix of tweet.\n",
        "TestSet = train[(train.gender=='male') | (train.gender=='female')]\n",
        "X_test=TestSet1[\"text\"]\n",
        "y_test=TestSet1[\"gender\"]\n",
        "Test=X_test.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8qbZFkXoL27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clean_Test=[]\n",
        "for i in Test:\n",
        "  Clean_Test.append(spacy_tokenizer(i))\n",
        "Test_Clean=[]\n",
        "for i in range(0, len(Clean_Test)):\n",
        "  Test_Clean.append(' '.join(Clean_Test[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW_1GEGuNeFw",
        "colab_type": "text"
      },
      "source": [
        "##Classifying\n",
        "Now, the funny part begins! As explain before, the first method chosen is the cosine-similarity. To do so, we created a function that will compute the cosine-similarity of each test tweet with our two documents (female's one and male's one). The function will classify the tweet accordingly to the highest cosine-similarity. In our case, as the base rate is *female*, in case of an equlality situation between the cosine-similarities, we will classify the tweet as a *female*. The model might be changed for the final version, for that purpose. we will check the base rate of all tweeter's users.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMtgjE4NiJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classification with Cosine Similarity\n",
        "def classifier(clean):\n",
        "  clean=cleaning(clean)\n",
        "  y_pred=[]\n",
        "  text=[Fem,Mal,clean]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  cosine =cosine_similarity(bow[2],bow)\n",
        "  if cosine[0][0]>=cosine[0][1]:\n",
        "    y_pred.append(\"female\")\n",
        "  else:\n",
        "    y_pred.append(\"male\")\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fULfmoTNO4HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#might take some time as we have a lot of data\n",
        "y_pred=[]\n",
        "for i in Test_Clean:\n",
        "  y_pred.append(classifier(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioop0aV6jcVl",
        "colab_type": "text"
      },
      "source": [
        "###Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inzS1gjdbM23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_pred,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbj7q5uodbGh",
        "colab_type": "text"
      },
      "source": [
        "We see that our accuracy is higher than the BaseRate of the model. It means that the accuracy will be higher by using our model than classifying every tweet as written by female. But the difference is not huge. Therefor, we will try with another model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys0QcggMe6rT",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender\n",
        "Here, you can input a tweet of your choice and our model will try to predict the author's gender.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxLGS_tOeXli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I won't buy you beer, but I will bring you pleasure, here is my paypal. Don't hesitate to give me money. Do you want nudes ? I am full shaved. I will cook for you and more if you are down for it ;) As my uncle is dead, I have no cash left, help me and I will cum for you ! Oops come ;).\n",
        "Tweet=input(\"Enter a Tweet: \")\n",
        "print('This tweet was probably writtent by a:',classifier(Tweet))\n",
        "BOW(Tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEKQdPKDhYWD",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression\n",
        "In this part, we will predict the gender with a logistic Regression. To do so, we will try to adapt a *Sentiment Analysis* model. The equivalent of the sentiment will be the gender. To do so, we won't use the merge documents for the training part. We will keep all tweets as an input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YevtietiKij",
        "colab_type": "text"
      },
      "source": [
        "##Data Cleaning\n",
        "For this model, we need to clean all our tweets one by one. This time, we won't use the description.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqer-dXTT2Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainSet = train[(train.gender=='male') | (train.gender=='female')]\n",
        "X_train=TrainSet[\"text\"]\n",
        "y_train=TrainSet[\"gender\"]\n",
        "Train=X_train.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-fEV7OeKgwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clean_Train=[]\n",
        "for i in Train:\n",
        "  Clean_Train.append(spacy_tokenizer(i))\n",
        "Train_Clean=[]\n",
        "for i in range(0, len(Clean_Train)):\n",
        "  Train_Clean.append(' '.join(Clean_Train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HnIIDgFjRts",
        "colab_type": "text"
      },
      "source": [
        "##Classifying\n",
        "For this model, we will use a cleaning function that was given during our DMML class (see lab 6.1). The cleaning methods works better with this model than the function we wrote ourself. However, our function is better with the cosine-similarity than that cleaning's function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kAcabThtwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier2 = LogisticRegression(solver=\"lbfgs\")\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier2', classifier2)])\n",
        "\n",
        "# model generation\n",
        "y_train=TrainSet1[\"gender\"]\n",
        "pipe.fit(Train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP1zS9kAZE3w",
        "colab_type": "text"
      },
      "source": [
        "###Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3VivyKRjAVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(Test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbLiJ_1DZRaf",
        "colab_type": "text"
      },
      "source": [
        "We conclude that the accuracy in this case is quite similar to the accuracy obtained with the cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZ-nevwcz_b",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV2qdQ7bc9RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tweet=input(\"Enter a Tweet: \")\n",
        "Tweet=[Tweet]\n",
        "print('This tweet was probably written by a:',pipe.predict(Tweet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCzWPwwQa_-",
        "colab_type": "text"
      },
      "source": [
        "#Decision Tree\n",
        "As we are not satisfied by our accuracy, we will try other methods. Here we will use the Decision Tree method. For this method, the input of the model cannot be a list of words. We will input array that can be represent graphically as bag of words. To construct this method, we took example of the Lab Session 7.1 of the DMML class. We will use the data that we clean previously and transform them in arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtrSBmB0tt9C",
        "colab_type": "text"
      },
      "source": [
        "##Data transformation\n",
        "In this part, we will transform ours lsits of words into array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445F877TQomv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_texts = Train_Clean\n",
        "#transform the list of words into array\n",
        "count = CountVectorizer()\n",
        "bow_train = count.fit_transform(Train_texts)\n",
        "bow_train.toarray()\n",
        "feature_names = count.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47KK5qQxQ64L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add a column with the gender and transfrom 'male' as 0 and 'female' as 1\n",
        "y_train=TrainSet1[\"gender\"]\n",
        "y_train= y_train.replace({'male':0})\n",
        "y_train = y_train.replace({'female':1})\n",
        "y_train=y_train.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-eOSVc7V8nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform the list of words into array\n",
        "y_test=TestSet1['gender']\n",
        "Texts_test = Test_Clean \n",
        "bow_test = count.transform(Texts_test)\n",
        "bow_test=bow_test.toarray()\n",
        "#Change the value of the test set as it matches the train one\n",
        "y_test=y_test.replace({'male':0})\n",
        "y_test=y_test.replace({'female':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UGj764WuHqZ",
        "colab_type": "text"
      },
      "source": [
        "##Bag Of Words DataFrame\n",
        "The columns of this dataframe represent all words available in our dataset. To win some time, we didn't use the english dictionnary in the cleaning process. We have some non-sense token but on the other hand, we can capture some words that are only use on social-networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxgG8E5aQ1wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a bag of words DataFrame\n",
        "BoW=pd.DataFrame(\n",
        "    bow_train.todense(), \n",
        "    columns=feature_names\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwK6LtVsQ-UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with n-gram 1 and 2, it might crash\n",
        "BoW['Gender']=y_train\n",
        "cols = list(BoW.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "BoW = BoW[cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZQY6zViRB6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Display the BagOfWords\n",
        "BoW.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po2qbk53RPQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "tfidf_train = tfidf.fit_transform(Train_texts)\n",
        "tfidf_train.toarray()\n",
        "TFIDF=pd.DataFrame(tfidf_train.todense(),columns=tfidf.get_feature_names())\n",
        "TFIDF['Gender']=y_train\n",
        "cols = list(TFIDF.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "TFIDF = TFIDF[cols]\n",
        "TFIDF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bycvt1kgsz8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_test=tfidf.transform(Texts_test)\n",
        "tfidf_test.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q_RloF3unfq",
        "colab_type": "text"
      },
      "source": [
        "##Dimensionality-Reduction\n",
        "As we saw in the last lecture, we can gain in accuracy and in computing time by applying dimensionality-reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcEjUDmTskrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy import sparse as sp\n",
        "clf = TruncatedSVD()\n",
        "Xpca_Test = clf.fit_transform(bow_test)\n",
        "Xpca_Train = clf.fit_transform(bow_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr6E_9bEuNeH",
        "colab_type": "text"
      },
      "source": [
        "##Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be5dxjLBQy20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the classifier, the max_depth parameter is defined thanks to a \"test\" done later\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth=781,random_state=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zTZFTT9uXJY",
        "colab_type": "text"
      },
      "source": [
        "###Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9VxKPKzQysL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model, first we no dimensionality reduction\n",
        "clf.fit(bow_train, y_train)\n",
        "clf.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMCMovywiNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(tfidf_train,y_train)\n",
        "clf.score(tfidf_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bce_kv_RfjNq",
        "colab_type": "text"
      },
      "source": [
        "Here, we will try to find the optimum depth of our decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuhgDWbfZCCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if you don't want to run it, optimum : Depth =781   Accuracy=58.2 % --> we may increase the range... or reduce the steps..\n",
        "max_acc=0\n",
        "depth=0\n",
        "for i in range(1,1000,5):\n",
        "  clf = DecisionTreeClassifier(criterion='entropy',max_depth=i,random_state=14)\n",
        "  clf.fit(bow_train, y_train)\n",
        "  if clf.score(bow_test,y_test) > max_acc:\n",
        "    max_acc= clf.score(bow_test,y_test)\n",
        "    depth=i\n",
        "    print('depth:', i,' acc =', max_acc )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh-LraSFiZj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train and test the model after the dimensionality reduction\n",
        "clf.fit(Xpca_Train, y_train)\n",
        "clf.score(Xpca_Test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ2V7K5vCB0Q",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4IP4AsLCBWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(bow_train, y_train)\n",
        "Tweet=input('Enter a Tweet: ')\n",
        "Tweet=[Tweet]\n",
        "bow_tweet= count.transform(Tweet)\n",
        "bow_tweet=bow_tweet.toarray()\n",
        "Gender=clf.predict(bow_tweet)\n",
        "if Gender ==0:\n",
        "  Gender='male'\n",
        "else:\n",
        "  Gender='female'\n",
        "print('This tweet was probably written by a:',Gender)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Zd5Rpdypfo",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydTCQenyET7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rclf=RandomForestClassifier(criterion='entropy',max_depth=451, random_state=14, n_estimators=76)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ymkhVZyykc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rclf.fit(bow_train,y_train)\n",
        "rclf.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUPKJspIISm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rclf.fit(tfidf_train,y_train)\n",
        "rclf.score(tfidf_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asHeE6vx4Yir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#depth: 371  acc = 0.5964444444444444\n",
        "max_acc=0\n",
        "depth=0\n",
        "for i in range(1,1000,5):\n",
        "  rclf=RandomForestClassifier(criterion='entropy',max_depth=i, random_state=14,n_estimators=10)\n",
        "  rclf.fit(bow_train, y_train)\n",
        "  if rclf.score(bow_test,y_test) > max_acc:\n",
        "    max_acc= rclf.score(bow_test,y_test)\n",
        "    depth=i\n",
        "    print('depth:', i,' acc =', max_acc )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGYHQreI5ouy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Nothing was higher than the combination depth=371 and n_estimators=76 --> to find the best combination, should have done iterations on the both parameters but would have taken to much time \n",
        "max_acc=0\n",
        "depth=0\n",
        "for i in range(1,1000,5):\n",
        "  rclf=RandomForestClassifier(criterion='entropy',max_depth=371, random_state=14,n_estimators=i)\n",
        "  rclf.fit(bow_train, y_train)\n",
        "  if rclf.score(bow_test,y_test) > max_acc:\n",
        "    max_acc= rclf.score(bow_test,y_test)\n",
        "    depth=i\n",
        "    print('n_estim:', i,' acc =', max_acc )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nb3pwAQHwHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rclf.fit(bow_train, y_train)\n",
        "Tweet=input('Enter a Tweet: ')\n",
        "Tweet=[Tweet]\n",
        "bow_tweet= count.transform(Tweet)\n",
        "bow_tweet=bow_tweet.toarray()\n",
        "Gender=rclf.predict(bow_tweet)\n",
        "if Gender ==0:\n",
        "  Gender='male'\n",
        "else:\n",
        "  Gender='female'\n",
        "print('This tweet was probably written by a:',Gender)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTBdbdotmLcr",
        "colab_type": "text"
      },
      "source": [
        "Now, from this part, we have clean all the data we need. So the end of the notebook will consist of training different models and computre their accuracy. That's why it will be less commented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V58Kqmetub5F",
        "colab_type": "text"
      },
      "source": [
        "#Basic Logistic Regression\n",
        "Let's try a more 'basic' regression. This one should not give weight to words as the one working as a sentiment analysis does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "celbkXGLD8bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "LR = LogisticRegressionCV(solver='lbfgs', cv=5,max_iter=1000, random_state=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MoYG9cJBtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Try without reduction\n",
        "LR.fit(bow_train,y_train)\n",
        "LR.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yWtPnHwrYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#try with TF-IDF\n",
        "LR.fit(tfidf_train,y_train)\n",
        "LR.score(tfidf_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjKlpugjkKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#With dimensionality reduction\n",
        "LR.fit(Xpca_Train, y_train)\n",
        "LR.score(Xpca_Test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYWqHQqzC9dm",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWtRSiBfC9DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR.fit(bow_train, y_train)\n",
        "Tweet=input('Enter a Tweet: ')\n",
        "Tweet=[Tweet]\n",
        "bow_tweet= count.transform(Tweet)\n",
        "bow_tweet=bow_tweet.toarray()\n",
        "Gender=LR.predict(bow_tweet)\n",
        "if Gender ==0:\n",
        "  Gender='male'\n",
        "else:\n",
        "  Gender='female'\n",
        "print('This tweet was probably written by a:',Gender)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRjE8EfHugUQ",
        "colab_type": "text"
      },
      "source": [
        "#KNN Classification\n",
        "The last method we will try is a the k-nearest-neighbor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkdhBFe9OnXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=10, weights='distance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxRLEqfLjoIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(bow_train,y_train)\n",
        "knn.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEdPSDhXwvjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(tfidf_train,y_train)\n",
        "knn.score(tfidf_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAIDJvfijp7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(Xpca_Train,y_train)\n",
        "knn.score(Xpca_Test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c59M0eUDLwT",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8WarPsHDA9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(bow_train,y_train)\n",
        "Tweet=input('Enter a Tweet: ')\n",
        "Tweet=[Tweet]\n",
        "bow_tweet= count.transform(Tweet)\n",
        "bow_tweet=bow_tweet.toarray()\n",
        "Gender=knn.predict(bow_tweet)\n",
        "if Gender ==0:\n",
        "  Gender='male'\n",
        "else:\n",
        "  Gender='female'\n",
        "print('This tweet was probably written by a:',Gender)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUlReYD03eGP",
        "colab_type": "text"
      },
      "source": [
        "#Gender Prediction\n",
        "In this part, we will use all the methods tested before. The goal is to take all the predictions and to see which vote (male or female) is the most frequent. To do so, we will use the basic version of each method. (i.e. the one without dimensionality reduction). For the fit, we chose the one with the best accuracy for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZn_NC4pKY2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#re-fit the algo\n",
        "knn.fit(tfidf_train,y_train)\n",
        "LR.fit(bow_train,y_train)\n",
        "clf.fit(bow_train,y_train)\n",
        "rclf.fit(bow_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZQadk73Ea3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GenderPrediction():\n",
        "  Results=[]\n",
        "  Tweet=input('Enter a Tweet or a Text: ')\n",
        "  Results.append(classifier(Tweet))\n",
        "  Tweet=[Tweet]\n",
        "  Results.append(pipe.predict(Tweet))\n",
        "  bow_tweet= count.transform(Tweet)\n",
        "  tfidf_tweet=tfidf.transform(Tweet)\n",
        "  tfidf_tweet=tfidf_tweet.toarray()\n",
        "  bow_tweet=bow_tweet.toarray()\n",
        "  Results.append(knn.predict(tfidf_tweet))\n",
        "  Results.append(LR.predict(bow_tweet))\n",
        "  Results.append(clf.predict(bow_tweet))\n",
        "  Results.append(rclf.predict(bow_tweet))\n",
        "  Pred_F=0\n",
        "  Pred_M=0\n",
        "  for i in Results:\n",
        "    if i[0] == 0 or i[0] =='male':\n",
        "      Pred_M +=1\n",
        "    else:\n",
        "      Pred_F+=1\n",
        "  if Pred_M>Pred_F:\n",
        "    print('This tweet was probably written by a male.')\n",
        "  else:\n",
        "    print('This tweet was probably written by a female.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq-KtxSS3yX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GenderPrediction()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}