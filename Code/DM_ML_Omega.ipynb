{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM-ML_Omega.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg8WfKU0BZWD",
        "colab_type": "text"
      },
      "source": [
        "#**Project Omega**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoCIUXEFBbVS",
        "colab_type": "text"
      },
      "source": [
        "#Project's Goal\n",
        "The main research goal is to set a program that will predict the gender of the author of a tweet and we could extend the model to any text.<br><br>\n",
        "To do so, we will use some text analytics techniques seen in class. Those techniques are tokenization, BOW (bag of words), TF-IDF stylometrie, cosine-similarity and try to adapt some sentiment-analysis.<br><br>\n",
        "In term of business, with this idea we aim to enhence marketing targeting. Third party advertisement companies can have better knowledge on Twitter’s gender distribution. Thus, they can advise companies that want to make advertisement on social network like Twitter. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTvvGBLBcYx",
        "colab_type": "text"
      },
      "source": [
        "##Importation and Installation of methods\n",
        "For this project, we will use different packages. The main part will be about text mining. For this, we will use packages seen in class, which are *spacy*, *nltk* and *enchant*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZnVKnB6BxRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "!pip install spacy\n",
        "!apt install -qq enchant\n",
        "!pip install pyenchant\n",
        "!pip install nltk\n",
        "!python -m spacy download en\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!pip install chart_studio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkSWdDbB7J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import enchant\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score\n",
        "import collections\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9AV_STwSQIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/XaviJunior/omega/Data/Data/gender-classifier-DFE-791531.csv',encoding=\"latin-1\")\n",
        "textgender=data[[\"gender\",'text',\"description\"]]\n",
        "textgender=textgender.dropna()\n",
        "X=textgender[['text','description']]\n",
        "y=textgender[\"gender\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n",
        "train= pd.concat([X_train.reset_index(drop='Tru‌​e'),y_train.reset_index(drop='Tru‌​e')],axis=1)\n",
        "test=pd.concat([X_test.reset_index(drop='Tru‌​e'),y_test.reset_index(drop='Tru‌​e')],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYv0JhESDI-P",
        "colab_type": "text"
      },
      "source": [
        "#Cosine Similarity\n",
        "The first method we will apply, is the cosine-similarity. As we seen in class, this method is often use to do text-similarity.<br>\n",
        "Our first idea, was to do the cosine similarity between all train tweets and test tweets and then classify the tweet according the most similar one. But we realised that the data set was to big and it would take too much time to go through all the test tweets. (Our code runs an entire night and was not finished) <br>\n",
        "So our second idea was to merge all train tweet and the description of the account (to gain text) as two documents, one with text written by male and another by female. With that, we will be able to gain information such as most common words used by each gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWCLpvkhCJrf",
        "colab_type": "text"
      },
      "source": [
        "##Data Cleaning <br>\n",
        "We first began by separate tweet by gender. We made new tables, one for male and one for female. <br>\n",
        "We are not interested by all the feautres (columns), we kept the \"gender\", the \"text\" and the \"name\" for the brand. <br>\n",
        "We chose to split the data by gender to be able to construct general BOW for each gender. As a tweet is necessarily written by a male or a female (only take into account biological gender), for our train and test set, we decide to ingonre tweet written by *brand* or tweet labeled as *unknown*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJkdmIQCAM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#New Table with Male Only and Split in Test/Train Data\n",
        "Male = train[train['gender'] == 'male']\n",
        "Maletext=Male['text']\n",
        "MaleDes=Male['description']\n",
        "ym=Male[\"gender\"]\n",
        "ListMale=Maletext.values.tolist()+MaleDes.values.tolist()\n",
        "\n",
        "#New Table with Female Only and split in Test/Train Data\n",
        "Female = train[train['gender'] == 'female']\n",
        "Femaletext=Female['text']\n",
        "FemaleDes=Female['description']\n",
        "yf=Female[\"gender\"]\n",
        "ListFemale=Femaletext.values.tolist()+FemaleDes.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCL_Td_rGR60",
        "colab_type": "text"
      },
      "source": [
        "###Merging\n",
        "Now that we create different table for both gender. We will merge all the tweets in two documents, for one male and one for female. We do that because we are interested to know which words are the most used by male and female."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsI2CkaPGSbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merge all Male Text in a single string\n",
        "TextMale=\" \"\n",
        "for i in range(0,len(ListMale)):\n",
        "  TextMale=TextMale+ListMale[i]\n",
        "textmale=TextMale.lower()\n",
        "\n",
        "#Merge all Female Text in a single string\n",
        "TextFemale=\" \"\n",
        "for i in range(0,len(ListFemale)):\n",
        "  TextFemale=TextFemale+ListFemale[i]\n",
        "textfemale=TextFemale.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67Xvy94GfVN",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization, Stop Words, Lemmatization\n",
        "Here, we created the function that will do the text cleaning.<br>\n",
        "First, the tokenization will allow us to separate each word and to be able to calulate the frequencie of each single word. The tokenization's technique chosen is the white-space one.<br>\n",
        "Now that we have tokens, we want to clean the text by removing stop words and other tokens such as \"\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\\x89\\x9d_\\x95ü\\x8f\". To do so, we will use a stop words list available in *spacy* and filter words that are not in the english dictionnary available on *pyenchant*. We know that by using an ensglish dictionnary we may lose some expression that are used on twitter. But for us, it was the only sustainable solution to filter non-sense tokens. We will also test this function without the dictionnary to see which one gives use the best accuracy. <br>\n",
        "We finish the function by doing some lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhW7tPE3Ga-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning function\n",
        "def cleaning(input):\n",
        "  nlp = English()\n",
        "  Doc=nlp(input)\n",
        "  Token = []\n",
        "#Check if words in english dictionnary\n",
        "  for token in Doc:\n",
        "    Token.append(token.text)\n",
        "  Words=[]\n",
        "  d = enchant.Dict(\"en_US\")\n",
        "  Text=''\n",
        "  for i in Token:\n",
        "    if d.check(i)==True and i != ' ': #comment this line to try without dictionnary\n",
        "      Text+=' '+i         #remove an indenatation to try without dictionnary\n",
        "  doc=nlp(Text)\n",
        "#Remove stop words and punctuation\n",
        "  for word in doc:\n",
        "    if word.is_stop==False and word.is_punct==False:\n",
        "      Words.append(word)\n",
        "  words=''\n",
        "#Lemmatization\n",
        "  for j in Words:\n",
        "    lemm=lemmatizer.lemmatize(str(j))\n",
        "    words+=lemm+' '\n",
        "  words=words.lower()\n",
        "  return(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJqRkoIB1jAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizer found in the DMML class lab 6.1\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpjF0ekVIXnI",
        "colab_type": "text"
      },
      "source": [
        "Now, we will apply this function to our two documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CNvczhFIdED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fem=cleaning(textfemale)\n",
        "Mal=cleaning(textmale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_2vlPzcJJ43",
        "colab_type": "text"
      },
      "source": [
        "##Bag Of Words (BOW)\n",
        "Here we are going to create a table with a line per gender. The columns are all the words used on the train tweet of our dataset. As we merge all the tweet, it would have made no sense to set bag of words of n-gramns other than one. Because at some point some BOW would have been wirtten by two different people. We create two functions, the first is to plot the BOW for our *female* and *male* documents, the second one will plot the BOW with these documents and the tweet for which we want to predict the gender.<br>\n",
        "As we only have 2 documents, doing some TF-IDF would not make a lot of sence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqcjybuJJPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creation and ploting of bag of words for two documents\n",
        "def bagofwords(Fem,Mal):\n",
        "  text=[Fem,Mal]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  feature_names = count.get_feature_names()\n",
        "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male'])\n",
        "  return BagOfWords.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7FRgWtUKAee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creation and ploting of bag of words for three documents\n",
        "def BOW(clean):\n",
        "  clean=cleaning(clean)\n",
        "  text=[Fem,Mal,clean]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  feature_names = count.get_feature_names()\n",
        "  BagOfWords=pd.DataFrame(bow.todense(),columns=feature_names, index=['Female','Male','Test'])\n",
        "  return BagOfWords.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6k4E3hhKMIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bagofwords(Fem,Mal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfENjkIWKqzi",
        "colab_type": "text"
      },
      "source": [
        "##Cleaning of the Test Data\n",
        "This part is a little bit more technical as the first cleaning. In the first case, we merged all tweet so we had only two documents. <br>\n",
        "Now, we want to clean tweet by tweet and have several clean documents. As we cleaned the *train* set, we need to apply the same method to the *test* set. The goal of this section is to build a list of *cleaned tweets* by gender. <br>\n",
        "In this part, as our goal is to predict gender by tweet only, we won't take into account the account's description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQA_9O6iKqd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here, we will set the test set as random mix of tweet.\n",
        "TestSetM = test[test['gender'] == 'male']\n",
        "TestSetF = test[test['gender'] == 'female']\n",
        "TestSet=TestSetM.append(TestSetF)\n",
        "TestSet1=TestSet.sample(frac=1)\n",
        "X_test=TestSet1[\"text\"]\n",
        "y_test=TestSet1[\"gender\"]\n",
        "Test=X_test.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8qbZFkXoL27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clean_Test=[]\n",
        "for i in Test:\n",
        "  Clean_Test.append(spacy_tokenizer(i))\n",
        "Test_Clean=[]\n",
        "for i in range(0, len(Clean_Test)):\n",
        "  Test_Clean.append(' '.join(Clean_Test[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW_1GEGuNeFw",
        "colab_type": "text"
      },
      "source": [
        "##Classifying\n",
        "Now, the funny part can begin. As explain before, the first method chosen is the cosine-similarity. To do so, we created a function that will compute the cosine-similarity of each test tweet with our two documents (female's one and male's one). The function will classify the tweet according the highest cosine-similarity. In our case, as the base rate is *female*, in case of equlality between the cosine-similarities, we classify the tweet as a *female*. The model might be changed for the final version, for that, we will check the base rate of all tweeter's users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMtgjE4NiJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classification with Cosine Similarity\n",
        "def classifier(clean):\n",
        "  clean=cleaning(clean)\n",
        "  y_pred=[]\n",
        "  text=[Fem,Mal,clean]\n",
        "  count = CountVectorizer()\n",
        "  bow = count.fit_transform(text)\n",
        "  cosine =cosine_similarity(bow[2],bow)\n",
        "  if cosine[0][0]>=cosine[0][1]:\n",
        "    y_pred.append(\"female\")\n",
        "  else:\n",
        "    y_pred.append(\"male\")\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fULfmoTNO4HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#might take some time as we have a lot of data\n",
        "y_pred=[]\n",
        "for i in Test_Clean:\n",
        "  y_pred.append(classifier(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioop0aV6jcVl",
        "colab_type": "text"
      },
      "source": [
        "###Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inzS1gjdbM23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_pred,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbj7q5uodbGh",
        "colab_type": "text"
      },
      "source": [
        "We see that our accuracy is higher than the BaseRate of the model. It means that the accuracy will be higher by using our model than classify every tweet as written by female. But the difference is not huge. We will try another model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys0QcggMe6rT",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender\n",
        "Here, you can input a tweet of your choice and our model will try to predict the author's gender.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxLGS_tOeXli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I won't buy you beer, but I will bring you pleasure, here is my paypal. Don't hesitate to give me money. Do you want nudes ? I am full shaved. I will cook for you and more if you are down for it ;) As my uncle is dead, I have no cash left, help me and I will cum for you ! Oops come ;).\n",
        "Tweet=input(\"Enter a Tweet: \")\n",
        "print('This tweet was probably writtent by a:',classifier(Tweet))\n",
        "BOW(Tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEKQdPKDhYWD",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression\n",
        "In this part, we will predict the gender according a logistic Regression. To do so, we will try to adapt a *Sentiment Analysis* model. The equivalent of the sentiment will be the gender. To do that, we won't use the merge documents for the training part. We will keep all tweets as an input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YevtietiKij",
        "colab_type": "text"
      },
      "source": [
        "##Data Cleaning\n",
        "For this model, we need to clean all our tweets one by one and we won't use the description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqer-dXTT2Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainSetM = train[train['gender'] == 'male']\n",
        "TrainSetF = train[train['gender'] == 'female']\n",
        "TrainSet=TrainSetM.append(TrainSetF)\n",
        "TrainSet1=TrainSet.sample(frac=1)\n",
        "X_train=TrainSet1[\"text\"]\n",
        "y_train=TrainSet1[\"gender\"]\n",
        "Train=X_train.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-fEV7OeKgwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clean_Train=[]\n",
        "for i in Train:\n",
        "  Clean_Train.append(spacy_tokenizer(i))\n",
        "Train_Clean=[]\n",
        "for i in range(0, len(Clean_Train)):\n",
        "  Train_Clean.append(' '.join(Clean_Train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HnIIDgFjRts",
        "colab_type": "text"
      },
      "source": [
        "##Classifying\n",
        "For this model, we will use a cleaning function that was given during our DMML class (see lab 6.1). The cleaning methods works better with this model than the functio we wrote ourself. But our function is better with the cosine-similarity than that cleaning's function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kAcabThtwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier2 = LogisticRegression(solver=\"lbfgs\")\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier2', classifier2)])\n",
        "\n",
        "# model generation\n",
        "y_train=TrainSet1[\"gender\"]\n",
        "pipe.fit(Train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP1zS9kAZE3w",
        "colab_type": "text"
      },
      "source": [
        "###Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3VivyKRjAVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(Test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbLiJ_1DZRaf",
        "colab_type": "text"
      },
      "source": [
        "We see that the accuracy in this case is quite equal to the accuracy obtained with the cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZ-nevwcz_b",
        "colab_type": "text"
      },
      "source": [
        "###Predict Tweet's gender\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV2qdQ7bc9RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tweet=input(\"Enter a Tweet: \")\n",
        "Tweet=[Tweet]\n",
        "print('This tweet was probably written by a:',pipe.predict(Tweet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCzWPwwQa_-",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445F877TQomv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "texts = Train_Clean\n",
        "# using default tokenizer \n",
        "count = CountVectorizer()\n",
        "bow_train = count.fit_transform(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxgG8E5aQ1wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_train.toarray()\n",
        "\n",
        "feature_names = count.get_feature_names()\n",
        "BoW=pd.DataFrame(\n",
        "    bow_train.todense(), \n",
        "    columns=feature_names\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47KK5qQxQ64L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=TrainSet1[\"gender\"]\n",
        "y_train= y_train.replace({'male':0})\n",
        "y_train = y_train.replace({'female':1})\n",
        "y_train=y_train.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwK6LtVsQ-UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with n-gram 1 and 2, it might crash\n",
        "BoW['Gender']=y_train\n",
        "cols = list(BoW.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "BoW = BoW[cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZQY6zViRB6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BoW.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be5dxjLBQy20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion='entropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9VxKPKzQysL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=TrainSet1['gender']\n",
        "clf.fit(bow_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-eOSVc7V8nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_test = Test\n",
        "# using default tokenizer \n",
        "bow_test = count.transform(texts_test)\n",
        "\n",
        "# Show feature matrix\n",
        "bow_test=bow_test.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0EjU9-7WI-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcEjUDmTskrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy import sparse as sp\n",
        "clf = TruncatedSVD(1000)\n",
        "Xpca_Test = clf.fit_transform(bow_test)\n",
        "Xpca_Train = clf.fit_transform(bow_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "celbkXGLD8bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "LR = LogisticRegressionCV(solver='lbfgs', cv=5,max_iter=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjKlpugjkKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR.fit(Xpca_Train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmW0mjsEP2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR.score(Xpca_Test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MoYG9cJBtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR.fit(bow_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY4xzt6RJFXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR.score(bow_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkdhBFe9OnXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auiQRObGOqu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(Xpca_Train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhSdokK1OuXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.score(Xpca_Test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po2qbk53RPQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "TFIDF=pd.DataFrame(features.todense(),columns=tfidf.get_feature_names())\n",
        "y_train=TrainSet1[\"gender\"]\n",
        "y_train=y_train.values.tolist()\n",
        "TFIDF['Gender']=y_train\n",
        "cols = list(TFIDF.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "TFIDF = TFIDF[cols]\n",
        "TFIDF= TFIDF.replace({'male':0})\n",
        "TFIDF = TFIDF.replace({'female':1})\n",
        "TFIDF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}